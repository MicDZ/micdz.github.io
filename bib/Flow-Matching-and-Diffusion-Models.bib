@misc{holderrieth2025introductionflowmatchingdiffusion,
      title={An Introduction to Flow Matching and Diffusion Models}, 
      author={Peter Holderrieth and Ezra Erives},
      year={2025},
      eprint={2506.02070},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2506.02070}, 
}
@misc{RN177,
   author = {Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
   title = {Denoising Diffusion Probabilistic Models},
   pages = {arXiv:2006.11239},
   month = {June},
   abstract = {We present high quality image synthesis results using diffusion probabilistic models, a class of latent variable models inspired by considerations from nonequilibrium thermodynamics. Our best results are obtained by training on a weighted variational bound designed according to a novel connection between diffusion probabilistic models and denoising score matching with Langevin dynamics, and our models naturally admit a progressive lossy decompression scheme that can be interpreted as a generalization of autoregressive decoding. On the unconditional CIFAR10 dataset, we obtain an Inception score of 9.46 and a state-of-the-art FID score of 3.17. On 256x256 LSUN, we obtain sample quality similar to ProgressiveGAN. Our implementation is available at https://github.com/hojonathanho/diffusion},
   keywords = {Computer Science - Machine Learning
Statistics - Machine Learning},
   DOI = {10.48550/arXiv.2006.11239},
   url = {https://arxiv.org/abs/2006.11239},
   year = {2020},
   type = {Electronic Article}
}

